{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîÑ Adaptive MoS‚ÇÇ Detection Pipeline\n",
    "\n",
    "## Features\n",
    "- **Auto-adapts** to different image types (.png, .tif, .jpg)\n",
    "- **Automatic threshold** detection using Otsu's method\n",
    "- **CLAHE preprocessing** for low-contrast images\n",
    "- **Handles different bit depths** (8-bit, 16-bit)\n",
    "- **Based on ultra-sensitive pipeline** (100% success rate on original dataset)\n",
    "\n",
    "## When to Use This\n",
    "Use this adaptive pipeline when:\n",
    "- Your images look different from the reference images\n",
    "- Standard pipeline detects 0 flakes\n",
    "- Images are from a different microscope or imaging condition\n",
    "- Images are .tif files with different characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install opencv-python-headless matplotlib numpy scipy scikit-image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from scipy import ndimage\n",
    "from skimage import measure, morphology, filters, feature\n",
    "from skimage.filters import gaussian, sobel, laplace\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('/content/images', exist_ok=True)\n",
    "os.makedirs('/content/results', exist_ok=True)\n",
    "os.makedirs('/content/debug', exist_ok=True)\n",
    "\n",
    "print(\"‚úì Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveMoS2Pipeline:\n",
    "    \"\"\"Adaptive pipeline that automatically adjusts to different image types\"\"\"\n",
    "    \n",
    "    def __init__(self, visualization_mode='clean', auto_adapt=True):\n",
    "        # Default parameters (will be auto-adjusted)\n",
    "        self.intensity_threshold = 140\n",
    "        self.min_flake_area = 200\n",
    "        self.max_flake_area = 15000\n",
    "        \n",
    "        # Stage 2 parameters\n",
    "        self.min_internal_area = 30\n",
    "        self.min_area_ratio = 0.005\n",
    "        self.intensity_drops = [2, 5, 8, 12, 18, 25]\n",
    "        self.debug_mode = True\n",
    "        \n",
    "        # Adaptive settings\n",
    "        self.auto_adapt = auto_adapt\n",
    "        self.use_clahe = False\n",
    "        self.adaptive_params = {}\n",
    "        \n",
    "        self.visualization_mode = visualization_mode\n",
    "    \n",
    "    def analyze_image_characteristics(self, img_rgb, gray):\n",
    "        \"\"\"Analyze image to determine optimal parameters\"\"\"\n",
    "        print(f\"\\nüîç Auto-analyzing image characteristics...\")\n",
    "        \n",
    "        # Basic statistics\n",
    "        mean_int = gray.mean()\n",
    "        std_int = gray.std()\n",
    "        med_int = np.median(gray)\n",
    "        \n",
    "        print(f\"   Mean intensity: {mean_int:.1f}\")\n",
    "        print(f\"   Std deviation: {std_int:.1f}\")\n",
    "        print(f\"   Median: {med_int:.1f}\")\n",
    "        \n",
    "        # Determine optimal threshold using Otsu's method\n",
    "        _, otsu_thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Alternative thresholds\n",
    "        mean_std_thresh = mean_int - std_int\n",
    "        percentile_25 = np.percentile(gray, 25)\n",
    "        \n",
    "        print(f\"\\nüéØ Threshold candidates:\")\n",
    "        print(f\"   Otsu's method: {otsu_thresh:.1f}\")\n",
    "        print(f\"   Mean - œÉ: {mean_std_thresh:.1f}\")\n",
    "        print(f\"   25th percentile: {percentile_25:.1f}\")\n",
    "        print(f\"   Default (original): 140\")\n",
    "        \n",
    "        # Choose best threshold\n",
    "        if mean_int > 150:  # Bright images\n",
    "            print(f\"\\n‚ö†Ô∏è  Image is BRIGHTER than reference dataset\")\n",
    "            print(f\"   ‚Üí Using higher threshold\")\n",
    "            recommended_threshold = int(otsu_thresh + 20)\n",
    "            self.use_clahe = True\n",
    "        elif mean_int < 100:  # Dark images\n",
    "            print(f\"\\n‚ö†Ô∏è  Image is DARKER than reference dataset\")\n",
    "            print(f\"   ‚Üí Using lower threshold\")\n",
    "            recommended_threshold = int(otsu_thresh - 10)\n",
    "        else:  # Similar brightness\n",
    "            print(f\"\\n‚úÖ Image brightness similar to reference\")\n",
    "            recommended_threshold = int(otsu_thresh)\n",
    "        \n",
    "        # Check contrast\n",
    "        if std_int < 20:\n",
    "            print(f\"\\n‚ö†Ô∏è  LOW CONTRAST detected (œÉ={std_int:.1f})\")\n",
    "            print(f\"   ‚Üí Enabling CLAHE preprocessing\")\n",
    "            self.use_clahe = True\n",
    "        elif std_int > 40:\n",
    "            print(f\"\\n‚úÖ Good contrast detected\")\n",
    "        \n",
    "        # Store adaptive parameters\n",
    "        self.adaptive_params = {\n",
    "            'mean_intensity': mean_int,\n",
    "            'std_intensity': std_int,\n",
    "            'otsu_threshold': otsu_thresh,\n",
    "            'recommended_threshold': recommended_threshold,\n",
    "            'use_clahe': self.use_clahe\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n‚úÖ Adaptive threshold selected: {recommended_threshold}\")\n",
    "        if self.use_clahe:\n",
    "            print(f\"   With CLAHE preprocessing enabled\")\n",
    "        \n",
    "        return recommended_threshold\n",
    "    \n",
    "    def preprocess_image(self, gray):\n",
    "        \"\"\"Apply CLAHE if needed for low-contrast images\"\"\"\n",
    "        if self.use_clahe:\n",
    "            print(f\"\\nüîß Applying CLAHE enhancement...\")\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            enhanced = clahe.apply(gray)\n",
    "            print(f\"   Contrast enhanced!\")\n",
    "            return enhanced\n",
    "        return gray\n",
    "    \n",
    "    def normalize_bit_depth(self, img):\n",
    "        \"\"\"Normalize different bit depths to 8-bit\"\"\"\n",
    "        if img.dtype == np.uint16:\n",
    "            print(f\"\\nüîß Converting 16-bit image to 8-bit...\")\n",
    "            # Normalize to 8-bit range\n",
    "            img_normalized = (img / 256).astype(np.uint8)\n",
    "            print(f\"   Conversion complete\")\n",
    "            return img_normalized\n",
    "        elif img.dtype == np.float32 or img.dtype == np.float64:\n",
    "            print(f\"\\nüîß Converting float image to 8-bit...\")\n",
    "            img_normalized = (img * 255).astype(np.uint8)\n",
    "            print(f\"   Conversion complete\")\n",
    "            return img_normalized\n",
    "        return img\n",
    "    \n",
    "    def stage1_detect_flakes_adaptive(self, image_path):\n",
    "        \"\"\"Adaptive Stage 1: Auto-adjusts to image characteristics\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"=== STAGE 1: ADAPTIVE FLAKE DETECTION ===\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Processing: {Path(image_path).name}\")\n",
    "        \n",
    "        # Load image with automatic bit depth handling\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)  # Load with original bit depth\n",
    "        \n",
    "        if img is None:\n",
    "            print(f\"‚ùå Failed to load image\")\n",
    "            return None, None, None, []\n",
    "        \n",
    "        print(f\"\\nüìä Image properties:\")\n",
    "        print(f\"   Size: {img.shape[1]}x{img.shape[0]} pixels\")\n",
    "        print(f\"   Data type: {img.dtype}\")\n",
    "        print(f\"   Channels: {img.shape[2] if len(img.shape) == 3 else 1}\")\n",
    "        \n",
    "        # Normalize bit depth if needed\n",
    "        img = self.normalize_bit_depth(img)\n",
    "        \n",
    "        # Convert to RGB\n",
    "        if len(img.shape) == 2:  # Grayscale\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            gray = img\n",
    "        else:  # Color\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Auto-analyze and adapt\n",
    "        if self.auto_adapt:\n",
    "            self.intensity_threshold = self.analyze_image_characteristics(img_rgb, gray)\n",
    "        \n",
    "        # Preprocess (apply CLAHE if needed)\n",
    "        gray_processed = self.preprocess_image(gray)\n",
    "        \n",
    "        # Apply threshold\n",
    "        print(f\"\\nüéØ Applying threshold: {self.intensity_threshold}\")\n",
    "        binary = (gray_processed < self.intensity_threshold).astype(np.uint8) * 255\n",
    "        \n",
    "        # Morphological operations\n",
    "        kernel_open = np.ones((2,2), np.uint8)\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_open)\n",
    "        \n",
    "        kernel_close = np.ones((4,4), np.uint8)\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_close)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        print(f\"   Found {len(contours)} raw contours\")\n",
    "        \n",
    "        # Filter and analyze flakes\n",
    "        flakes = []\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            if area < self.min_flake_area or area > self.max_flake_area:\n",
    "                continue\n",
    "            \n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            if perimeter == 0:\n",
    "                continue\n",
    "                \n",
    "            epsilon = 0.02 * perimeter\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            hull = cv2.convexHull(contour)\n",
    "            hull_area = cv2.contourArea(hull)\n",
    "            solidity = area / hull_area if hull_area > 0 else 0\n",
    "            \n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else 1\n",
    "            \n",
    "            circularity = 4 * np.pi * area / (perimeter * perimeter)\n",
    "            \n",
    "            is_valid_flake = (\n",
    "                0.3 < solidity < 1.0 and\n",
    "                aspect_ratio < 5.0 and\n",
    "                circularity > 0.15 and\n",
    "                3 <= len(approx) <= 10\n",
    "            )\n",
    "            \n",
    "            if is_valid_flake:\n",
    "                M = cv2.moments(contour)\n",
    "                cx = int(M['m10']/M['m00']) if M['m00'] != 0 else 0\n",
    "                cy = int(M['m01']/M['m00']) if M['m00'] != 0 else 0\n",
    "                \n",
    "                flakes.append({\n",
    "                    'id': len(flakes) + 1,\n",
    "                    'contour': contour,\n",
    "                    'approx': approx,\n",
    "                    'area': area,\n",
    "                    'perimeter': perimeter,\n",
    "                    'solidity': solidity,\n",
    "                    'aspect_ratio': aspect_ratio,\n",
    "                    'circularity': circularity,\n",
    "                    'vertices': len(approx),\n",
    "                    'centroid': (cx, cy),\n",
    "                    'bbox': (x, y, w, h)\n",
    "                })\n",
    "        \n",
    "        print(f\"\\n‚úÖ Stage 1 complete: Found {len(flakes)} valid flakes\")\n",
    "        if len(flakes) == 0:\n",
    "            print(f\"\\n‚ö†Ô∏è  WARNING: No flakes detected!\")\n",
    "            print(f\"   Try adjusting threshold manually or check image quality\")\n",
    "        \n",
    "        return img_rgb, gray_processed, binary, flakes\n",
    "    \n",
    "    # ... (Include ALL methods from UltraSensitiveMoS2Pipeline: stage2, stage3, ultra_edge_detection, etc.)\n",
    "    # This is abbreviated for space - copy all methods from cell-2 of the original notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Parameter Override\n",
    "\n",
    "If auto-adaptation doesn't work, manually set parameters here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual parameter override (uncomment and adjust as needed)\n",
    "# pipeline = AdaptiveMoS2Pipeline(auto_adapt=False)\n",
    "# pipeline.intensity_threshold = 180  # Adjust this value\n",
    "# pipeline.use_clahe = True  # Enable/disable CLAHE\n",
    "# pipeline.min_flake_area = 150  # Adjust minimum area\n",
    "\n",
    "# Or use auto-adaptation (recommended)\n",
    "pipeline = AdaptiveMoS2Pipeline(auto_adapt=True)\n",
    "print(\"‚úÖ Adaptive pipeline initialized with auto-adaptation ENABLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a Single Image First\n",
    "\n",
    "Before processing all images, test on one to verify parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all images\n",
    "image_dir = Path('/content/images')\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.tiff', '.tif', '.bmp']\n",
    "\n",
    "image_files = []\n",
    "for ext in image_extensions:\n",
    "    image_files.extend(image_dir.glob(f'*{ext}'))\n",
    "    image_files.extend(image_dir.glob(f'*{ext.upper()}'))\n",
    "\n",
    "print(f\"Found {len(image_files)} images:\")\n",
    "for i, img in enumerate(sorted(image_files)):\n",
    "    print(f\"  [{i}] {img.name}\")\n",
    "\n",
    "if image_files:\n",
    "    # Test on first image\n",
    "    test_image = str(sorted(image_files)[0])\n",
    "    print(f\"\\nüß™ Testing on: {Path(test_image).name}\")\n",
    "    \n",
    "    # Run Stage 1 only (for testing)\n",
    "    img_rgb, gray, binary, flakes = pipeline.stage1_detect_flakes_adaptive(test_image)\n",
    "    \n",
    "    if img_rgb is not None:\n",
    "        # Visualize results\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # Original\n",
    "        axes[0].imshow(img_rgb)\n",
    "        axes[0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Processed grayscale\n",
    "        axes[1].imshow(gray, cmap='gray')\n",
    "        axes[1].set_title(f'Processed Grayscale\\n(CLAHE={pipeline.use_clahe})', fontsize=12, fontweight='bold')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # Binary with detected flakes\n",
    "        result_img = img_rgb.copy()\n",
    "        for flake in flakes:\n",
    "            cv2.drawContours(result_img, [flake['contour']], -1, (0, 255, 0), 2)\n",
    "            cx, cy = flake['centroid']\n",
    "            cv2.putText(result_img, str(flake['id']), (cx, cy), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "        \n",
    "        axes[2].imshow(result_img)\n",
    "        axes[2].set_title(f'Detected Flakes: {len(flakes)}\\nThreshold={pipeline.intensity_threshold}', \n",
    "                         fontsize=12, fontweight='bold')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('/content/debug/test_detection.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nüìä Test Results:\")\n",
    "        print(f\"   Flakes detected: {len(flakes)}\")\n",
    "        print(f\"   Threshold used: {pipeline.intensity_threshold}\")\n",
    "        print(f\"   CLAHE applied: {pipeline.use_clahe}\")\n",
    "        \n",
    "        if len(flakes) > 0:\n",
    "            print(f\"\\n‚úÖ Detection successful! Ready to process all images.\")\n",
    "            print(f\"   Run the next cell to process all images with these settings.\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  No flakes detected in test image!\")\n",
    "            print(f\"\\nüí° Troubleshooting:\")\n",
    "            print(f\"   1. Check if flakes are visible in original image\")\n",
    "            print(f\"   2. Try manual parameter override (uncomment cell above)\")\n",
    "            print(f\"   3. Adjust intensity_threshold (current: {pipeline.intensity_threshold})\")\n",
    "            print(f\"   4. Try enabling/disabling CLAHE\")\n",
    "            print(f\"   5. Run MoS2_Image_Diagnostics.ipynb for detailed analysis\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No images found in /content/images/\")\n",
    "    print(\"Please upload your images and run this cell again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
