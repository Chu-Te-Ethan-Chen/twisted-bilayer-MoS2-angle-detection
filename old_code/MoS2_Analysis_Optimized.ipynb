{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Optimized MoS2 Flake Detection Pipeline\n",
        "\n",
        "## Improvements in This Version:\n",
        "- **Multiple color space analysis** (HSV, LAB, RGB)\n",
        "- **Adaptive thresholding** for varying lighting conditions\n",
        "- **Contrast enhancement** specifically for microscopy images\n",
        "- **Multiple detection methods** with result combination\n",
        "- **Interactive parameter tuning** for your specific images\n",
        "\n",
        "Upload your images to `/content/images/` and run the cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_dependencies"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install opencv-python-headless matplotlib numpy scipy scikit-image\n",
        "!pip install plotly ipywidgets\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import json\n",
        "from scipy import ndimage\n",
        "from skimage import measure, morphology, filters, segmentation, feature\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "import os\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Create directories\n",
        "os.makedirs('/content/images', exist_ok=True)\n",
        "os.makedirs('/content/results', exist_ok=True)\n",
        "os.makedirs('/content/debug', exist_ok=True)\n",
        "\n",
        "print(\"✓ Environment setup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "color_analysis"
      },
      "outputs": [],
      "source": [
        "def analyze_image_colors(image_path, sample_points=None):\n",
        "    \"\"\"Analyze color characteristics of the image to optimize detection parameters\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Convert to different color spaces\n",
        "    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
        "    lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
        "    \n",
        "    # Create interactive plot for color analysis\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    \n",
        "    # Original image\n",
        "    axes[0,0].imshow(img_rgb)\n",
        "    axes[0,0].set_title('Original Image')\n",
        "    axes[0,0].axis('off')\n",
        "    \n",
        "    # HSV channels\n",
        "    axes[0,1].imshow(hsv[:,:,0], cmap='hsv')\n",
        "    axes[0,1].set_title('HSV - Hue')\n",
        "    axes[0,1].axis('off')\n",
        "    \n",
        "    axes[0,2].imshow(hsv[:,:,1], cmap='gray')\n",
        "    axes[0,2].set_title('HSV - Saturation')\n",
        "    axes[0,2].axis('off')\n",
        "    \n",
        "    axes[1,0].imshow(hsv[:,:,2], cmap='gray')\n",
        "    axes[1,0].set_title('HSV - Value')\n",
        "    axes[1,0].axis('off')\n",
        "    \n",
        "    # LAB channels\n",
        "    axes[1,1].imshow(lab[:,:,1], cmap='RdYlGn_r')\n",
        "    axes[1,1].set_title('LAB - A channel (Green-Red)')\n",
        "    axes[1,1].axis('off')\n",
        "    \n",
        "    axes[1,2].imshow(lab[:,:,2], cmap='YlOrBr_r')\n",
        "    axes[1,2].set_title('LAB - B channel (Blue-Yellow)')\n",
        "    axes[1,2].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print color statistics\n",
        "    print(\"=== COLOR ANALYSIS ===\")\n",
        "    print(f\"HSV ranges:\")\n",
        "    print(f\"  Hue: {hsv[:,:,0].min()}-{hsv[:,:,0].max()}\")\n",
        "    print(f\"  Saturation: {hsv[:,:,1].min()}-{hsv[:,:,1].max()}\")\n",
        "    print(f\"  Value: {hsv[:,:,2].min()}-{hsv[:,:,2].max()}\")\n",
        "    print(f\"LAB ranges:\")\n",
        "    print(f\"  L: {lab[:,:,0].min()}-{lab[:,:,0].max()}\")\n",
        "    print(f\"  A: {lab[:,:,1].min()}-{lab[:,:,1].max()}\")\n",
        "    print(f\"  B: {lab[:,:,2].min()}-{lab[:,:,2].max()}\")\n",
        "    \n",
        "    return img_rgb, hsv, lab\n",
        "\n",
        "# Analyze the first image if available\n",
        "image_files = list(Path('/content/images').glob('*.png')) + list(Path('/content/images').glob('*.jpg'))\n",
        "if image_files:\n",
        "    print(f\"Analyzing colors in: {image_files[0].name}\")\n",
        "    img_rgb, hsv, lab = analyze_image_colors(str(image_files[0]))\n",
        "else:\n",
        "    print(\"No images found. Please upload images to /content/images/ first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "optimized_analyzer"
      },
      "outputs": [],
      "source": [
        "class OptimizedMoS2Analyzer:\n",
        "    def __init__(self):\n",
        "        self.debug_mode = True\n",
        "        self.results = {}\n",
        "    \n",
        "    def preprocess_image(self, image_path):\n",
        "        \"\"\"Enhanced preprocessing for microscopy images\"\"\"\n",
        "        img = cv2.imread(image_path)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Multiple preprocessing approaches\n",
        "        processed_images = {}\n",
        "        \n",
        "        # 1. CLAHE enhancement\n",
        "        lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "        l_enhanced = clahe.apply(l)\n",
        "        enhanced_lab = cv2.merge([l_enhanced, a, b])\n",
        "        processed_images['clahe'] = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)\n",
        "        \n",
        "        # 2. Histogram equalization\n",
        "        yuv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2YUV)\n",
        "        yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])\n",
        "        processed_images['hist_eq'] = cv2.cvtColor(yuv, cv2.COLOR_YUV2RGB)\n",
        "        \n",
        "        # 3. Gamma correction for better contrast\n",
        "        gamma = 1.2\n",
        "        processed_images['gamma'] = np.power(img_rgb / 255.0, gamma)\n",
        "        processed_images['gamma'] = (processed_images['gamma'] * 255).astype(np.uint8)\n",
        "        \n",
        "        return img_rgb, processed_images\n",
        "    \n",
        "    def detect_flakes_multiple_methods(self, image, enhanced_images):\n",
        "        \"\"\"Use multiple detection methods and combine results\"\"\"\n",
        "        all_flakes = []\n",
        "        debug_masks = {}\n",
        "        \n",
        "        # Method 1: HSV color-based detection (improved)\n",
        "        flakes1, mask1 = self.detect_hsv_method(enhanced_images['clahe'])\n",
        "        all_flakes.extend([(f, 'hsv') for f in flakes1])\n",
        "        debug_masks['hsv'] = mask1\n",
        "        \n",
        "        # Method 2: LAB color space detection\n",
        "        flakes2, mask2 = self.detect_lab_method(enhanced_images['clahe'])\n",
        "        all_flakes.extend([(f, 'lab') for f in flakes2])\n",
        "        debug_masks['lab'] = mask2\n",
        "        \n",
        "        # Method 3: Edge-based detection\n",
        "        flakes3, mask3 = self.detect_edge_method(enhanced_images['gamma'])\n",
        "        all_flakes.extend([(f, 'edge') for f in flakes3])\n",
        "        debug_masks['edge'] = mask3\n",
        "        \n",
        "        # Method 4: Adaptive threshold method\n",
        "        flakes4, mask4 = self.detect_adaptive_method(enhanced_images['hist_eq'])\n",
        "        all_flakes.extend([(f, 'adaptive') for f in flakes4])\n",
        "        debug_masks['adaptive'] = mask4\n",
        "        \n",
        "        # Combine and filter results\n",
        "        combined_flakes = self.combine_detections(all_flakes)\n",
        "        \n",
        "        return combined_flakes, debug_masks\n",
        "    \n",
        "    def detect_hsv_method(self, image):\n",
        "        \"\"\"Improved HSV-based detection with multiple color ranges\"\"\"\n",
        "        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "        \n",
        "        # Multiple color ranges for different MoS2 appearances\n",
        "        color_ranges = [\n",
        "            # Blue range (primary)\n",
        "            ([100, 30, 30], [140, 255, 255]),\n",
        "            # Purple range\n",
        "            ([140, 30, 30], [170, 255, 255]),\n",
        "            # Dark blue range\n",
        "            ([90, 50, 20], [120, 255, 200]),\n",
        "            # Light purple range\n",
        "            ([120, 20, 50], [160, 150, 255])\n",
        "        ]\n",
        "        \n",
        "        combined_mask = np.zeros(hsv.shape[:2], dtype=np.uint8)\n",
        "        \n",
        "        for lower, upper in color_ranges:\n",
        "            mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
        "            combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
        "        \n",
        "        # Morphological operations\n",
        "        kernel = np.ones((2,2), np.uint8)\n",
        "        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
        "        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)\n",
        "        \n",
        "        return self.extract_triangular_contours(combined_mask), combined_mask\n",
        "    \n",
        "    def detect_lab_method(self, image):\n",
        "        \"\"\"LAB color space detection focusing on blue/purple regions\"\"\"\n",
        "        lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
        "        \n",
        "        # Focus on B channel (blue-yellow axis) for blue/purple detection\n",
        "        b_channel = lab[:,:,2]\n",
        "        \n",
        "        # Create mask for blue regions (low B values indicate blue)\n",
        "        blue_mask = b_channel < 120  # Adjust this threshold\n",
        "        \n",
        "        # Also check A channel for purple regions\n",
        "        a_channel = lab[:,:,1]\n",
        "        purple_mask = a_channel > 135  # Higher A values for magenta/purple\n",
        "        \n",
        "        # Combine masks\n",
        "        combined_mask = np.logical_or(blue_mask, purple_mask).astype(np.uint8) * 255\n",
        "        \n",
        "        # Morphological operations\n",
        "        kernel = np.ones((3,3), np.uint8)\n",
        "        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
        "        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)\n",
        "        \n",
        "        return self.extract_triangular_contours(combined_mask), combined_mask\n",
        "    \n",
        "    def detect_edge_method(self, image):\n",
        "        \"\"\"Edge-based detection for flake boundaries\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        \n",
        "        # Multiple edge detection approaches\n",
        "        edges1 = cv2.Canny(gray, 30, 100)\n",
        "        edges2 = cv2.Canny(gray, 50, 150)\n",
        "        \n",
        "        # Combine edge maps\n",
        "        edges = cv2.bitwise_or(edges1, edges2)\n",
        "        \n",
        "        # Dilate to connect nearby edges\n",
        "        kernel = np.ones((3,3), np.uint8)\n",
        "        edges = cv2.dilate(edges, kernel, iterations=1)\n",
        "        \n",
        "        # Fill closed regions\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        filled_mask = np.zeros_like(edges)\n",
        "        \n",
        "        for contour in contours:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if area > 50:  # Filter small areas\n",
        "                cv2.fillPoly(filled_mask, [contour], 255)\n",
        "        \n",
        "        return self.extract_triangular_contours(filled_mask), filled_mask\n",
        "    \n",
        "    def detect_adaptive_method(self, image):\n",
        "        \"\"\"Adaptive thresholding method\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        \n",
        "        # Apply Gaussian blur\n",
        "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "        \n",
        "        # Adaptive threshold\n",
        "        adaptive_mask = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
        "                                            cv2.THRESH_BINARY_INV, 11, 2)\n",
        "        \n",
        "        # Morphological operations to clean up\n",
        "        kernel = np.ones((3,3), np.uint8)\n",
        "        adaptive_mask = cv2.morphologyEx(adaptive_mask, cv2.MORPH_CLOSE, kernel)\n",
        "        adaptive_mask = cv2.morphologyEx(adaptive_mask, cv2.MORPH_OPEN, kernel)\n",
        "        \n",
        "        return self.extract_triangular_contours(adaptive_mask), adaptive_mask\n",
        "    \n",
        "    def extract_triangular_contours(self, mask):\n",
        "        \"\"\"Extract triangular contours from binary mask\"\"\"\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        \n",
        "        triangular_flakes = []\n",
        "        for contour in contours:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if area < 50:  # Filter very small areas\n",
        "                continue\n",
        "            \n",
        "            # Calculate contour properties\n",
        "            perimeter = cv2.arcLength(contour, True)\n",
        "            if perimeter == 0:\n",
        "                continue\n",
        "            \n",
        "            # Approximate contour\n",
        "            epsilon = 0.01 * perimeter  # More sensitive approximation\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            \n",
        "            # Check shape characteristics\n",
        "            aspect_ratio = self.calculate_aspect_ratio(contour)\n",
        "            solidity = area / cv2.contourArea(cv2.convexHull(contour))\n",
        "            \n",
        "            # More flexible shape criteria\n",
        "            is_triangular = (\n",
        "                (3 <= len(approx) <= 6) or  # Allow some flexibility in vertex count\n",
        "                (0.6 < solidity < 1.0 and aspect_ratio < 3.0)  # Alternative criteria\n",
        "            )\n",
        "            \n",
        "            if is_triangular:\n",
        "                triangular_flakes.append({\n",
        "                    'contour': contour,\n",
        "                    'approx': approx,\n",
        "                    'area': area,\n",
        "                    'vertices': len(approx),\n",
        "                    'solidity': solidity,\n",
        "                    'aspect_ratio': aspect_ratio\n",
        "                })\n",
        "        \n",
        "        return triangular_flakes\n",
        "    \n",
        "    def calculate_aspect_ratio(self, contour):\n",
        "        \"\"\"Calculate aspect ratio of contour bounding box\"\"\"\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        return max(w, h) / min(w, h) if min(w, h) > 0 else 1\n",
        "    \n",
        "    def combine_detections(self, all_flakes):\n",
        "        \"\"\"Combine results from multiple detection methods\"\"\"\n",
        "        if not all_flakes:\n",
        "            return []\n",
        "        \n",
        "        # Simple combination - remove duplicates based on centroid distance\n",
        "        unique_flakes = []\n",
        "        \n",
        "        for flake_data, method in all_flakes:\n",
        "            flake_data['detection_method'] = method\n",
        "            \n",
        "            # Calculate centroid\n",
        "            M = cv2.moments(flake_data['contour'])\n",
        "            if M['m00'] == 0:\n",
        "                continue\n",
        "                \n",
        "            cx = M['m10'] / M['m00']\n",
        "            cy = M['m01'] / M['m00']\n",
        "            \n",
        "            # Check if similar flake already exists\n",
        "            is_duplicate = False\n",
        "            for existing_flake in unique_flakes:\n",
        "                existing_M = cv2.moments(existing_flake['contour'])\n",
        "                if existing_M['m00'] == 0:\n",
        "                    continue\n",
        "                    \n",
        "                existing_cx = existing_M['m10'] / existing_M['m00']\n",
        "                existing_cy = existing_M['m01'] / existing_M['m00']\n",
        "                \n",
        "                distance = np.sqrt((cx - existing_cx)**2 + (cy - existing_cy)**2)\n",
        "                if distance < 30:  # Threshold for considering duplicates\n",
        "                    # Keep the larger flake\n",
        "                    if flake_data['area'] > existing_flake['area']:\n",
        "                        unique_flakes.remove(existing_flake)\n",
        "                        unique_flakes.append(flake_data)\n",
        "                    is_duplicate = True\n",
        "                    break\n",
        "            \n",
        "            if not is_duplicate:\n",
        "                unique_flakes.append(flake_data)\n",
        "        \n",
        "        return unique_flakes\n",
        "    \n",
        "    def visualize_debug_results(self, image, flakes, debug_masks):\n",
        "        \"\"\"Visualize debug information for all detection methods\"\"\"\n",
        "        fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
        "        \n",
        "        # Original image\n",
        "        axes[0,0].imshow(image)\n",
        "        axes[0,0].set_title('Original Image')\n",
        "        axes[0,0].axis('off')\n",
        "        \n",
        "        # Detection masks\n",
        "        mask_titles = ['HSV Method', 'LAB Method', 'Edge Method', 'Adaptive Method']\n",
        "        mask_keys = ['hsv', 'lab', 'edge', 'adaptive']\n",
        "        \n",
        "        for i, (key, title) in enumerate(zip(mask_keys, mask_titles)):\n",
        "            row = (i + 1) // 3\n",
        "            col = (i + 1) % 3\n",
        "            if key in debug_masks:\n",
        "                axes[row, col].imshow(debug_masks[key], cmap='gray')\n",
        "            axes[row, col].set_title(title)\n",
        "            axes[row, col].axis('off')\n",
        "        \n",
        "        # Combined result\n",
        "        result_img = image.copy()\n",
        "        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]\n",
        "        \n",
        "        for i, flake in enumerate(flakes):\n",
        "            color = colors[i % len(colors)]\n",
        "            cv2.drawContours(result_img, [flake['contour']], -1, color, 2)\n",
        "            \n",
        "            # Add flake number and method\n",
        "            M = cv2.moments(flake['contour'])\n",
        "            if M['m00'] != 0:\n",
        "                cx = int(M['m10']/M['m00'])\n",
        "                cy = int(M['m01']/M['m00'])\n",
        "                cv2.putText(result_img, f\"{i+1}({flake['detection_method']})\", \n",
        "                          (cx-20, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
        "        \n",
        "        axes[2,2].imshow(result_img)\n",
        "        axes[2,2].set_title(f'Combined Results ({len(flakes)} flakes)')\n",
        "        axes[2,2].axis('off')\n",
        "        \n",
        "        # Fill empty subplot\n",
        "        axes[2,1].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "# Initialize optimized analyzer\n",
        "analyzer = OptimizedMoS2Analyzer()\n",
        "print(\"✓ Optimized MoS2 Analyzer initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_optimized_detection"
      },
      "outputs": [],
      "source": [
        "# Run optimized detection on all images\n",
        "image_dir = Path('/content/images')\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.tiff', '.bmp']\n",
        "\n",
        "image_files = []\n",
        "for ext in image_extensions:\n",
        "    image_files.extend(image_dir.glob(f'*{ext}'))\n",
        "    image_files.extend(image_dir.glob(f'*{ext.upper()}'))\n",
        "\n",
        "print(f\"Found {len(image_files)} images to process with optimized detection\\n\")\n",
        "\n",
        "for image_path in image_files:\n",
        "    print(f\"Processing: {image_path.name}\")\n",
        "    \n",
        "    try:\n",
        "        # Preprocess with multiple enhancement methods\n",
        "        original_img, enhanced_images = analyzer.preprocess_image(str(image_path))\n",
        "        \n",
        "        # Apply multiple detection methods\n",
        "        flakes, debug_masks = analyzer.detect_flakes_multiple_methods(original_img, enhanced_images)\n",
        "        \n",
        "        print(f\"  ✓ Found {len(flakes)} flakes using combined methods\")\n",
        "        \n",
        "        # Show method breakdown\n",
        "        method_counts = {}\n",
        "        for flake in flakes:\n",
        "            method = flake['detection_method']\n",
        "            method_counts[method] = method_counts.get(method, 0) + 1\n",
        "        \n",
        "        print(f\"  Detection breakdown: {method_counts}\")\n",
        "        \n",
        "        # Visualize debug results\n",
        "        debug_fig = analyzer.visualize_debug_results(original_img, flakes, debug_masks)\n",
        "        plt.savefig(f'/content/debug/{image_path.stem}_debug.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        # Save detailed flake information\n",
        "        flake_data = []\n",
        "        for i, flake in enumerate(flakes):\n",
        "            flake_info = {\n",
        "                'id': i + 1,\n",
        "                'area': float(flake['area']),\n",
        "                'vertices': int(flake['vertices']),\n",
        "                'solidity': float(flake['solidity']),\n",
        "                'aspect_ratio': float(flake['aspect_ratio']),\n",
        "                'detection_method': flake['detection_method']\n",
        "            }\n",
        "            flake_data.append(flake_info)\n",
        "        \n",
        "        # Save results\n",
        "        results = {\n",
        "            'filename': image_path.name,\n",
        "            'total_flakes': len(flakes),\n",
        "            'method_breakdown': method_counts,\n",
        "            'flake_details': flake_data\n",
        "        }\n",
        "        \n",
        "        with open(f'/content/results/{image_path.stem}_optimized_results.json', 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "        \n",
        "        print(f\"  ✓ Results saved to /content/results/{image_path.stem}_optimized_results.json\\n\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Error processing {image_path.name}: {str(e)}\\n\")\n",
        "        continue\n",
        "\n",
        "print(\"=== OPTIMIZED DETECTION COMPLETE ===\")\n",
        "print(\"Check the debug visualizations above to see how each method performed.\")\n",
        "print(\"Results are saved in /content/results/ and debug images in /content/debug/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "interactive_tuning"
      },
      "outputs": [],
      "source": [
        "# Interactive parameter tuning (run this if results still need improvement)\n",
        "def test_hsv_parameters(image_path, h_min=90, h_max=170, s_min=20, s_max=255, v_min=20, v_max=255):\n",
        "    \"\"\"Test different HSV parameters interactively\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
        "    \n",
        "    # Create mask with custom parameters\n",
        "    lower = np.array([h_min, s_min, v_min])\n",
        "    upper = np.array([h_max, s_max, v_max])\n",
        "    mask = cv2.inRange(hsv, lower, upper)\n",
        "    \n",
        "    # Apply morphological operations\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "    \n",
        "    # Find and count contours\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    valid_contours = [c for c in contours if cv2.contourArea(c) > 50]\n",
        "    \n",
        "    # Visualize results\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    \n",
        "    axes[0].imshow(img_rgb)\n",
        "    axes[0].set_title('Original')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    axes[1].imshow(mask, cmap='gray')\n",
        "    axes[1].set_title(f'Mask (H:{h_min}-{h_max}, S:{s_min}-{s_max}, V:{v_min}-{v_max})')\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    result_img = img_rgb.copy()\n",
        "    cv2.drawContours(result_img, valid_contours, -1, (255, 0, 0), 2)\n",
        "    axes[2].imshow(result_img)\n",
        "    axes[2].set_title(f'Detected: {len(valid_contours)} objects')\n",
        "    axes[2].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return len(valid_contours)\n",
        "\n",
        "# Test with your image (adjust path as needed)\n",
        "if image_files:\n",
        "    test_image = str(image_files[0])\n",
        "    print(\"Testing different HSV parameters...\")\n",
        "    print(\"Try adjusting these values to improve detection:\")\n",
        "    \n",
        "    # Test different parameter combinations\n",
        "    test_params = [\n",
        "        (90, 170, 20, 255, 20, 255),  # Wide range\n",
        "        (100, 140, 30, 255, 30, 200),  # Blue focus\n",
        "        (140, 170, 30, 255, 30, 200),  # Purple focus\n",
        "        (90, 160, 40, 200, 40, 180),   # Mid-tone focus\n",
        "    ]\n",
        "    \n",
        "    for i, (h_min, h_max, s_min, s_max, v_min, v_max) in enumerate(test_params):\n",
        "        print(f\"\\nTest {i+1}: H({h_min}-{h_max}), S({s_min}-{s_max}), V({v_min}-{v_max})\")\n",
        "        count = test_hsv_parameters(test_image, h_min, h_max, s_min, s_max, v_min, v_max)\n",
        "        \n",
        "    print(\"\\n=== TUNING RECOMMENDATIONS ===\")\n",
        "    print(\"1. If too many false positives: increase minimum saturation/value\")\n",
        "    print(\"2. If missing flakes: expand hue range or decrease saturation/value minimums\")\n",
        "    print(\"3. Update the parameters in the detect_hsv_method() function above\")\n",
        "else:\n",
        "    print(\"No images available for parameter tuning. Please upload images first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optimization_guide"
      },
      "source": [
        "## Optimization Guide\n",
        "\n",
        "### If Detection is Still Not Accurate:\n",
        "\n",
        "1. **Analyze the debug visualizations above** to see which method works best\n",
        "2. **Use the interactive parameter tuning** to find better HSV ranges\n",
        "3. **Modify detection parameters** in the code:\n",
        "   - Adjust color ranges in `detect_hsv_method()`\n",
        "   - Change area thresholds in `extract_triangular_contours()`\n",
        "   - Modify morphological operations kernel sizes\n",
        "\n",
        "### Key Parameters to Adjust:\n",
        "- **HSV color ranges**: `([h_min, s_min, v_min], [h_max, s_max, v_max])`\n",
        "- **Minimum area**: Currently 50, increase to filter noise\n",
        "- **Epsilon for contour approximation**: Currently 0.01 * perimeter\n",
        "- **Morphological kernel size**: Currently (2,2) or (3,3)\n",
        "\n",
        "### Next Steps:\n",
        "Once Stage 1 detection is optimized, we can proceed to:\n",
        "- **Stage 2**: Multilayer structure identification\n",
        "- **Stage 3**: Twist angle calculations\n"
      ]
    }
  ]
}