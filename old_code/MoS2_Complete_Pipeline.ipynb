{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Complete MoS2 Analysis Pipeline - All 3 Stages\n",
    "\n",
    "## Based on your feedback, this notebook:\n",
    "- **Stage 1**: Uses threshold < 140 (which worked well for your images)\n",
    "- **Stage 2**: Detects multilayer structures within flakes  \n",
    "- **Stage 3**: Calculates twist angles between layers\n",
    "\n",
    "## Fixed Issues:\n",
    "- ✅ Matplotlib subplot error fixed\n",
    "- ✅ Optimized for threshold 140 detection\n",
    "- ✅ Added noise filtering for better results\n",
    "- ✅ Complete 3-stage pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install opencv-python-headless matplotlib numpy scipy scikit-image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from scipy import ndimage\n",
    "from skimage import measure, morphology, filters\n",
    "import os\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('/content/images', exist_ok=True)\n",
    "os.makedirs('/content/results', exist_ok=True)\n",
    "os.makedirs('/content/debug', exist_ok=True)\n",
    "\n",
    "print(\"✓ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "complete_analyzer"
   },
   "outputs": [],
   "source": "    def find_internal_structures(self, roi_gray, roi_mask, offset_x, offset_y):\n        \"\"\"Find internal structures within a flake ROI\"\"\"\n        internal_structures = []\n        \n        # Method 1: Edge detection within the flake\n        edges = cv2.Canny(roi_gray, 30, 90)\n        edges = cv2.bitwise_and(edges, roi_mask)\n        \n        # Dilate edges slightly to connect gaps\n        kernel = np.ones((2,2), np.uint8)\n        edges = cv2.dilate(edges, kernel, iterations=1)\n        \n        # Find internal contours\n        contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        \n        for contour in contours:\n            area = cv2.contourArea(contour)\n            \n            # Check if this internal structure is significant\n            roi_area = np.sum(roi_mask > 0)  # Fixed: count non-zero pixels properly\n            area_ratio = area / roi_area if roi_area > 0 else 0\n            \n            if area > 100 and area_ratio > 0.05:  # At least 5% of the flake area\n                # Adjust coordinates back to full image\n                adjusted_contour = contour + [offset_x, offset_y]\n                \n                # Check if it's roughly triangular\n                epsilon = 0.03 * cv2.arcLength(contour, True)\n                approx = cv2.approxPolyDP(contour, epsilon, True)\n                \n                if 3 <= len(approx) <= 7:  # Roughly polygonal\n                    internal_structures.append({\n                        'contour': adjusted_contour,\n                        'approx': approx + [offset_x, offset_y],\n                        'area': area,\n                        'vertices': len(approx)\n                    })\n        \n        # Method 2: Intensity-based detection of darker regions within flake\n        masked_roi = cv2.bitwise_and(roi_gray, roi_mask)\n        if masked_roi.max() > 0:\n            # Find darker regions within the flake\n            mask_pixels = masked_roi[roi_mask > 0]\n            if len(mask_pixels) > 0:  # Check if we have valid pixels\n                mean_intensity = mask_pixels.mean()\n                dark_threshold = mean_intensity - 10  # Slightly darker than average\n                \n                dark_regions = (masked_roi < dark_threshold) & (roi_mask > 0)\n                dark_regions = dark_regions.astype(np.uint8) * 255\n                \n                # Clean up dark regions\n                kernel = np.ones((3,3), np.uint8)\n                dark_regions = cv2.morphologyEx(dark_regions, cv2.MORPH_OPEN, kernel)\n                \n                # Find contours of dark regions\n                dark_contours, _ = cv2.findContours(dark_regions, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n                \n                for contour in dark_contours:\n                    area = cv2.contourArea(contour)\n                    if area > 150:  # Minimum size for internal structure\n                        # Check if not already found by edge method\n                        adjusted_contour = contour + [offset_x, offset_y]\n                        \n                        # Simple duplicate check\n                        is_duplicate = False\n                        for existing in internal_structures:\n                            if abs(existing['area'] - area) < 50:  # Similar area\n                                is_duplicate = True\n                                break\n                        \n                        if not is_duplicate:\n                            epsilon = 0.03 * cv2.arcLength(contour, True)\n                            approx = cv2.approxPolyDP(contour, epsilon, True)\n                            \n                            internal_structures.append({\n                                'contour': adjusted_contour,\n                                'approx': approx + [offset_x, offset_y],\n                                'area': area,\n                                'vertices': len(approx),\n                                'detection_method': 'intensity'\n                            })\n        \n        return internal_structures"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_pipeline"
   },
   "outputs": [],
   "source": [
    "# Run complete pipeline on all images\n",
    "image_dir = Path('/content/images')\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.tiff', '.bmp']\n",
    "\n",
    "image_files = []\n",
    "for ext in image_extensions:\n",
    "    image_files.extend(image_dir.glob(f'*{ext}'))\n",
    "    image_files.extend(image_dir.glob(f'*{ext.upper()}'))\n",
    "\n",
    "print(f\"Found {len(image_files)} images to process\\n\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for image_path in image_files:\n",
    "    try:\n",
    "        # Run complete pipeline\n",
    "        results = pipeline.process_complete_pipeline(str(image_path))\n",
    "        \n",
    "        # Save visualization\n",
    "        plt.figure(results['figure'].number)\n",
    "        plt.savefig(f'/content/results/{image_path.stem}_complete_analysis.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed results\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"DETAILED RESULTS\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        flakes = results['flakes']\n",
    "        multilayer_flakes = results['multilayer_flakes']\n",
    "        angle_results = results['angle_results']\n",
    "        \n",
    "        print(f\"\\nFLAKE SUMMARY:\")\n",
    "        for flake in flakes:\n",
    "            layer_info = f\" ({flake['layer_count']}L)\" if flake.get('is_multilayer') else \" (1L)\"\n",
    "            print(f\"  Flake {flake['id']}: Area={flake['area']:.0f}px, \"\n",
    "                  f\"Vertices={flake['vertices']}, Solidity={flake['solidity']:.2f}{layer_info}\")\n",
    "        \n",
    "        if angle_results:\n",
    "            print(f\"\\nTWIST ANGLES:\")\n",
    "            for result in angle_results:\n",
    "                print(f\"  Flake {result['flake_id']}: {result['average_twist']:.1f}° \"\n",
    "                      f\"(from {len(result['twist_measurements'])} measurements)\")\n",
    "                for i, measurement in enumerate(result['twist_measurements']):\n",
    "                    print(f\"    Layer {i+1}: {measurement['twist_angle']:.1f}° \"\n",
    "                          f\"(area: {measurement['internal_area']:.0f}px)\")\n",
    "        \n",
    "        # Save detailed JSON results\n",
    "        json_data = {\n",
    "            'filename': image_path.name,\n",
    "            'analysis_summary': {\n",
    "                'total_flakes': len(flakes),\n",
    "                'multilayer_flakes': len(multilayer_flakes),\n",
    "                'bilayer_structures': len(angle_results)\n",
    "            },\n",
    "            'flake_details': [],\n",
    "            'twist_angle_data': []\n",
    "        }\n",
    "        \n",
    "        # Save flake details\n",
    "        for flake in flakes:\n",
    "            flake_data = {\n",
    "                'id': flake['id'],\n",
    "                'area': float(flake['area']),\n",
    "                'vertices': int(flake['vertices']),\n",
    "                'solidity': float(flake['solidity']),\n",
    "                'aspect_ratio': float(flake['aspect_ratio']),\n",
    "                'is_multilayer': bool(flake.get('is_multilayer', False)),\n",
    "                'layer_count': int(flake.get('layer_count', 1)),\n",
    "                'centroid': flake['centroid']\n",
    "            }\n",
    "            json_data['flake_details'].append(flake_data)\n",
    "        \n",
    "        # Save twist angle data\n",
    "        for result in angle_results:\n",
    "            angle_data = {\n",
    "                'flake_id': result['flake_id'],\n",
    "                'main_angle': float(result['main_angle']),\n",
    "                'average_twist': float(result['average_twist']),\n",
    "                'individual_measurements': [\n",
    "                    {\n",
    "                        'twist_angle': float(m['twist_angle']),\n",
    "                        'internal_area': float(m['internal_area'])\n",
    "                    } for m in result['twist_measurements']\n",
    "                ]\n",
    "            }\n",
    "            json_data['twist_angle_data'].append(angle_data)\n",
    "        \n",
    "        # Save to file\n",
    "        with open(f'/content/results/{image_path.stem}_complete_results.json', 'w') as f:\n",
    "            json.dump(json_data, f, indent=2)\n",
    "        \n",
    "        all_results.append(json_data)\n",
    "        print(f\"\\n✓ Complete results saved for {image_path.name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {image_path.name}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "# Final summary\n",
    "if all_results:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FINAL SUMMARY - ALL IMAGES\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    total_flakes = sum(r['analysis_summary']['total_flakes'] for r in all_results)\n",
    "    total_multilayer = sum(r['analysis_summary']['multilayer_flakes'] for r in all_results)\n",
    "    total_bilayer = sum(r['analysis_summary']['bilayer_structures'] for r in all_results)\n",
    "    \n",
    "    print(f\"Images processed: {len(all_results)}\")\n",
    "    print(f\"Total flakes detected: {total_flakes}\")\n",
    "    print(f\"Total multilayer structures: {total_multilayer}\")\n",
    "    print(f\"Total bilayer structures with twist angles: {total_bilayer}\")\n",
    "    \n",
    "    if total_flakes > 0:\n",
    "        print(f\"Multilayer detection rate: {total_multilayer/total_flakes*100:.1f}%\")\n",
    "    \n",
    "    # Collect all twist angles\n",
    "    all_twist_angles = []\n",
    "    for result in all_results:\n",
    "        for angle_data in result['twist_angle_data']:\n",
    "            all_twist_angles.append(angle_data['average_twist'])\n",
    "    \n",
    "    if all_twist_angles:\n",
    "        print(f\"\\nTwist angle statistics:\")\n",
    "        print(f\"  Total measurements: {len(all_twist_angles)}\")\n",
    "        print(f\"  Mean: {np.mean(all_twist_angles):.1f}°\")\n",
    "        print(f\"  Median: {np.median(all_twist_angles):.1f}°\")\n",
    "        print(f\"  Range: {np.min(all_twist_angles):.1f}° - {np.max(all_twist_angles):.1f}°\")\n",
    "        print(f\"  Standard deviation: {np.std(all_twist_angles):.1f}°\")\n",
    "    \n",
    "    # Save overall summary\n",
    "    with open('/content/results/complete_pipeline_summary.json', 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n✓ Complete pipeline results saved to /content/results/\")\n",
    "else:\n",
    "    print(\"No images were successfully processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results_guide"
   },
   "source": [
    "## Results Interpretation Guide\n",
    "\n",
    "### Output Files:\n",
    "- **`[filename]_complete_analysis.png`**: Visual summary of all 3 stages\n",
    "- **`[filename]_complete_results.json`**: Detailed numerical data\n",
    "- **`complete_pipeline_summary.json`**: Summary of all processed images\n",
    "\n",
    "### Stage Results:\n",
    "1. **Stage 1 (Blue outlines)**: All detected MoS2 flakes\n",
    "2. **Stage 2 (Green/Cyan outlines)**: Multilayer structures with internal features\n",
    "3. **Stage 3 (Orange outlines + angles)**: Bilayer twist angles in degrees\n",
    "\n",
    "### Key Metrics:\n",
    "- **Layer count**: Number of layers detected (1L, 2L, 3L, etc.)\n",
    "- **Twist angles**: Rotation between overlapping triangular layers\n",
    "- **Detection rate**: Percentage of flakes showing multilayer structure\n",
    "\n",
    "### Quality Indicators:\n",
    "- **Good detection**: Clear triangular outlines, reasonable twist angles (0-60°)\n",
    "- **False positives**: Very small areas, irregular shapes, extreme angles\n",
    "- **Missed structures**: Manual inspection may reveal additional multilayer regions\n",
    "\n",
    "### Next Steps:\n",
    "If results need refinement, adjust these parameters in the code:\n",
    "- `intensity_threshold` (currently 140)\n",
    "- `min_flake_area` (currently 200)\n",
    "- Internal structure detection sensitivity\n"
   ]
  }
 ]
}