{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoS‚ÇÇ Image Diagnostic Tool\n",
    "\n",
    "## Purpose\n",
    "This notebook analyzes new MoS‚ÇÇ images to understand why detection is failing and recommends optimal parameters.\n",
    "\n",
    "## Instructions\n",
    "1. Upload your images to `/content/images/` in Google Colab\n",
    "2. Run all cells\n",
    "3. Review the diagnostic visualizations and parameter recommendations\n",
    "4. Update `MoS2_UltraSensitive.ipynb` with the recommended parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import required packages\n",
    "!pip install opencv-python-headless matplotlib numpy scipy scikit-image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('/content/images', exist_ok=True)\n",
    "os.makedirs('/content/diagnostics', exist_ok=True)\n",
    "\n",
    "print(\"‚úì Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def analyze_image_characteristics(image_path):\n    \"\"\"Analyze image characteristics and intensity distribution\"\"\"\n    print(f\"\\n{'='*80}\")\n    print(f\"Analyzing: {Path(image_path).name}\")\n    print(f\"{'='*80}\")\n\n    # Load image\n    img = cv2.imread(str(image_path))\n    if img is None:\n        print(f\"‚ùå Failed to load image: {image_path}\")\n        return None\n\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n\n    # Image statistics\n    print(f\"\\nüìä Image Statistics:\")\n    print(f\"   Size: {img.shape[1]} x {img.shape[0]} pixels\")\n    print(f\"   Channels: {img.shape[2] if len(img.shape) == 3 else 1}\")\n    print(f\"   Data type: {img.dtype}\")\n\n    # Intensity statistics\n    print(f\"\\nüí° Intensity Statistics (Grayscale):\")\n    print(f\"   Mean: {gray.mean():.2f}\")\n    print(f\"   Median: {np.median(gray):.2f}\")\n    print(f\"   Std Dev: {gray.std():.2f}\")\n    print(f\"   Min: {gray.min()}\")\n    print(f\"   Max: {gray.max()}\")\n    print(f\"   Range: {gray.max() - gray.min()}\")\n\n    # Percentiles\n    percentiles = [5, 10, 25, 50, 75, 90, 95]\n    print(f\"\\nüìà Intensity Percentiles:\")\n    for p in percentiles:\n        print(f\"   {p}th: {np.percentile(gray, p):.2f}\")\n\n    # Find potential thresholds\n    print(f\"\\nüéØ Suggested Detection Thresholds:\")\n\n    # Method 1: Mean - std\n    threshold_1 = gray.mean() - gray.std()\n    print(f\"   Mean - 1œÉ: {threshold_1:.1f}\")\n\n    # Method 2: Otsu's method\n    otsu_val, _ = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    # Robust conversion to scalar\n    if isinstance(otsu_val, np.ndarray):\n        otsu_threshold = float(otsu_val.flat[0])\n    else:\n        otsu_threshold = float(otsu_val)\n    print(f\"   Otsu's method: {otsu_threshold:.1f}\")\n\n    # Method 3: 25th percentile\n    threshold_25 = np.percentile(gray, 25)\n    print(f\"   25th percentile: {threshold_25:.1f}\")\n\n    # Method 4: Triangle method\n    tri_val, _ = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_TRIANGLE)\n    # Robust conversion to scalar\n    if isinstance(tri_val, np.ndarray):\n        ret_triangle = float(tri_val.flat[0])\n    else:\n        ret_triangle = float(tri_val)\n    print(f\"   Triangle method: {ret_triangle:.1f}\")\n\n    # Color channel analysis\n    if len(img.shape) == 3:\n        print(f\"\\nüé® RGB Channel Statistics:\")\n        for i, channel_name in enumerate(['Red', 'Green', 'Blue']):\n            channel = img_rgb[:, :, i]\n            print(f\"   {channel_name}: Mean={channel.mean():.2f}, \"\n                  f\"Std={channel.std():.2f}, Range=[{channel.min()}-{channel.max()}]\")\n\n    return {\n        'path': str(image_path),\n        'name': Path(image_path).name,\n        'shape': img.shape,\n        'gray_stats': {\n            'mean': float(gray.mean()),\n            'median': float(np.median(gray)),\n            'std': float(gray.std()),\n            'min': int(gray.min()),\n            'max': int(gray.max())\n        },\n        'suggested_thresholds': {\n            'mean_minus_std': float(threshold_1),\n            'otsu': float(otsu_threshold),\n            'percentile_25': float(threshold_25),\n            'triangle': float(ret_triangle)\n        },\n        'img_rgb': img_rgb,\n        'gray': gray\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_threshold_effects(analysis_results):\n",
    "    \"\"\"Visualize how different thresholds affect detection\"\"\"\n",
    "\n",
    "    for result in analysis_results:\n",
    "        if result is None:\n",
    "            continue\n",
    "\n",
    "        img_rgb = result['img_rgb']\n",
    "        gray = result['gray']\n",
    "        name = result['name']\n",
    "\n",
    "        # Test multiple thresholds\n",
    "        test_thresholds = [\n",
    "            ('Current (140)', 140),\n",
    "            ('Otsu', result['suggested_thresholds']['otsu']),\n",
    "            ('Mean-œÉ', result['suggested_thresholds']['mean_minus_std']),\n",
    "            ('25th %ile', result['suggested_thresholds']['percentile_25']),\n",
    "            ('Triangle', result['suggested_thresholds']['triangle']),\n",
    "            ('Mean', gray.mean())\n",
    "        ]\n",
    "\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(20, 20))\n",
    "\n",
    "        # Original image\n",
    "        axes[0, 0].imshow(img_rgb)\n",
    "        axes[0, 0].set_title('Original Image', fontsize=14, fontweight='bold')\n",
    "        axes[0, 0].axis('off')\n",
    "\n",
    "        # Grayscale\n",
    "        axes[0, 1].imshow(gray, cmap='gray')\n",
    "        axes[0, 1].set_title('Grayscale', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].axis('off')\n",
    "\n",
    "        # Histogram\n",
    "        axes[0, 2].hist(gray.ravel(), bins=256, range=(0, 256), color='blue', alpha=0.7)\n",
    "        axes[0, 2].axvline(140, color='red', linestyle='--', linewidth=2, label='Current (140)')\n",
    "        for label, thresh in test_thresholds[1:]:\n",
    "            axes[0, 2].axvline(thresh, linestyle='--', alpha=0.6, linewidth=1.5, label=f'{label}: {thresh:.0f}')\n",
    "        axes[0, 2].set_title('Intensity Histogram with Thresholds', fontsize=14, fontweight='bold')\n",
    "        axes[0, 2].set_xlabel('Intensity', fontsize=12)\n",
    "        axes[0, 2].set_ylabel('Frequency', fontsize=12)\n",
    "        axes[0, 2].legend(fontsize=9, loc='best')\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "        # Test different thresholds\n",
    "        for idx, (label, threshold) in enumerate(test_thresholds):\n",
    "            row = (idx + 3) // 3\n",
    "            col = (idx + 3) % 3\n",
    "\n",
    "            binary = (gray < threshold).astype(np.uint8) * 255\n",
    "\n",
    "            # Apply morphological operations (same as in pipeline)\n",
    "            kernel_open = np.ones((2, 2), np.uint8)\n",
    "            binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_open)\n",
    "\n",
    "            kernel_close = np.ones((4, 4), np.uint8)\n",
    "            binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "            # Find contours\n",
    "            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Filter by area\n",
    "            valid_contours = [c for c in contours if 200 <= cv2.contourArea(c) <= 15000]\n",
    "\n",
    "            # Draw results\n",
    "            result_img = img_rgb.copy()\n",
    "            cv2.drawContours(result_img, valid_contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "            axes[row, col].imshow(result_img)\n",
    "            axes[row, col].set_title(f'{label}: {threshold:.1f}\\n{len(valid_contours)} flakes detected',\n",
    "                                    fontsize=12, fontweight='bold')\n",
    "            axes[row, col].axis('off')\n",
    "\n",
    "        plt.suptitle(f'Threshold Diagnostic Analysis: {name}', fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save figure\n",
    "        output_path = f'/content/diagnostics/{Path(name).stem}_threshold_diagnosis.png'\n",
    "        plt.savefig(output_path, dpi=200, bbox_inches='tight')\n",
    "        print(f\"üíæ Saved diagnostic visualization: {output_path}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_parameters(analysis_results):\n",
    "    \"\"\"Recommend optimal parameters based on analysis\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üéØ PARAMETER RECOMMENDATIONS\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    if not analysis_results or all(r is None for r in analysis_results):\n",
    "        print(\"‚ùå No valid analysis results\")\n",
    "        return None\n",
    "\n",
    "    # Filter out None results\n",
    "    valid_results = [r for r in analysis_results if r is not None]\n",
    "\n",
    "    # Aggregate statistics\n",
    "    mean_intensities = [r['gray_stats']['mean'] for r in valid_results]\n",
    "    otsu_thresholds = [r['suggested_thresholds']['otsu'] for r in valid_results]\n",
    "    mean_minus_std_thresholds = [r['suggested_thresholds']['mean_minus_std'] for r in valid_results]\n",
    "\n",
    "    avg_mean = np.mean(mean_intensities)\n",
    "    avg_otsu = np.mean(otsu_thresholds)\n",
    "    avg_mean_std = np.mean(mean_minus_std_thresholds)\n",
    "\n",
    "    print(f\"\\nüìä Aggregated Statistics Across {len(valid_results)} Images:\")\n",
    "    print(f\"   Average mean intensity: {avg_mean:.1f}\")\n",
    "    print(f\"   Average Otsu threshold: {avg_otsu:.1f}\")\n",
    "    print(f\"   Average Mean-œÉ threshold: {avg_mean_std:.1f}\")\n",
    "    print(f\"   Current threshold: 140\")\n",
    "    print(f\"   Difference: {140 - avg_mean:.1f} from mean\")\n",
    "\n",
    "    # Recommendations\n",
    "    print(f\"\\nüí° Recommended Parameter Updates:\")\n",
    "\n",
    "    # Choose best threshold\n",
    "    recommended_threshold = int(avg_otsu)\n",
    "    \n",
    "    print(f\"\\n1. intensity_threshold:\")\n",
    "    print(f\"   Current: 140\")\n",
    "    print(f\"   Recommended: {recommended_threshold}\")\n",
    "    print(f\"   Reasoning: Based on Otsu's method average across all images\")\n",
    "\n",
    "    print(f\"\\n2. Image characteristics assessment:\")\n",
    "    if avg_mean > 150:\n",
    "        print(f\"   ‚ö†Ô∏è  Images are BRIGHTER than reference (mean={avg_mean:.1f} vs ~120)\")\n",
    "        print(f\"   ‚Üí Flakes may be less visible (lower contrast)\")\n",
    "        print(f\"   ‚Üí Consider INCREASING threshold to {int(avg_otsu + 20)}\")\n",
    "        print(f\"   ‚Üí May need CLAHE (Contrast Limited Adaptive Histogram Equalization)\")\n",
    "        recommended_threshold = int(avg_otsu + 20)\n",
    "    elif avg_mean < 100:\n",
    "        print(f\"   ‚ö†Ô∏è  Images are DARKER than reference (mean={avg_mean:.1f} vs ~120)\")\n",
    "        print(f\"   ‚Üí Lower threshold needed\")\n",
    "        print(f\"   ‚Üí May need more aggressive morphological filtering\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Images have similar brightness to reference\")\n",
    "\n",
    "    # Check contrast\n",
    "    avg_std = np.mean([r['gray_stats']['std'] for r in valid_results])\n",
    "    print(f\"\\n3. Contrast assessment:\")\n",
    "    print(f\"   Average std deviation: {avg_std:.1f}\")\n",
    "    if avg_std < 20:\n",
    "        print(f\"   ‚ö†Ô∏è  LOW CONTRAST - Flakes may be hard to distinguish\")\n",
    "        print(f\"   ‚Üí Strongly recommend adding CLAHE preprocessing\")\n",
    "        print(f\"   ‚Üí Consider histogram equalization\")\n",
    "    elif avg_std > 40:\n",
    "        print(f\"   ‚úÖ Good contrast - standard detection should work\")\n",
    "    else:\n",
    "        print(f\"   ‚ö™ Moderate contrast - may benefit from enhancement\")\n",
    "\n",
    "    # Generate code snippet\n",
    "    print(f\"\\nüìù Code Update Snippet for MoS2_UltraSensitive.ipynb:\")\n",
    "    print(f\"```python\")\n",
    "    print(f\"# In __init__ method, update:\")\n",
    "    print(f\"self.intensity_threshold = {recommended_threshold}  # Updated from 140\")\n",
    "    print(f\"\")\n",
    "    if avg_mean > 150 or avg_std < 20:\n",
    "        print(f\"# Add CLAHE preprocessing in stage1_detect_flakes, after loading image:\")\n",
    "        print(f\"clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\")\n",
    "        print(f\"gray = clahe.apply(gray)  # Apply before thresholding\")\n",
    "    print(f\"```\")\n",
    "\n",
    "    return {\n",
    "        'recommended_threshold': recommended_threshold,\n",
    "        'avg_mean_intensity': avg_mean,\n",
    "        'avg_otsu_threshold': avg_otsu,\n",
    "        'avg_std': avg_std,\n",
    "        'needs_clahe': avg_mean > 150 or avg_std < 20\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main analysis\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üî¨ MoS2 Image Diagnostic Tool\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Find images\n",
    "image_dir = Path('/content/images')\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.tiff', '.tif', '.bmp']\n",
    "\n",
    "image_files = []\n",
    "for ext in image_extensions:\n",
    "    image_files.extend(image_dir.glob(f'*{ext}'))\n",
    "    image_files.extend(image_dir.glob(f'*{ext.upper()}'))\n",
    "\n",
    "print(f\"\\nFound {len(image_files)} images to analyze:\")\n",
    "for img in sorted(image_files):\n",
    "    print(f\"   - {img.name}\")\n",
    "\n",
    "if not image_files:\n",
    "    print(\"‚ùå No images found in /content/images/\")\n",
    "    print(\"Please upload your images and run this cell again.\")\n",
    "else:\n",
    "    # Analyze each image\n",
    "    analysis_results = []\n",
    "    for img_path in sorted(image_files):\n",
    "        try:\n",
    "            result = analyze_image_characteristics(str(img_path))\n",
    "            analysis_results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error analyzing {img_path.name}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            analysis_results.append(None)\n",
    "\n",
    "    # Visualize threshold effects\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìä Generating Diagnostic Visualizations\")\n",
    "    print(f\"{'='*80}\")\n",
    "    visualize_threshold_effects(analysis_results)\n",
    "\n",
    "    # Generate recommendations\n",
    "    recommendations = recommend_parameters(analysis_results)\n",
    "\n",
    "    # Save recommendations to JSON\n",
    "    if recommendations:\n",
    "        recommendations_path = '/content/diagnostics/parameter_recommendations.json'\n",
    "\n",
    "        # Add individual image results\n",
    "        recommendations['individual_results'] = []\n",
    "        for r in analysis_results:\n",
    "            if r is not None:\n",
    "                recommendations['individual_results'].append({\n",
    "                    'name': r['name'],\n",
    "                    'gray_stats': r['gray_stats'],\n",
    "                    'suggested_thresholds': r['suggested_thresholds']\n",
    "                })\n",
    "\n",
    "        with open(recommendations_path, 'w') as f:\n",
    "            json.dump(recommendations, f, indent=2)\n",
    "\n",
    "        print(f\"\\nüíæ Saved recommendations to: {recommendations_path}\")\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"‚úÖ Diagnostic Analysis Complete!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nüìÅ Results saved to: /content/diagnostics/\")\n",
    "    print(f\"\\nNext steps:\")\n",
    "    print(f\"1. Review diagnostic images above\")\n",
    "    print(f\"2. Download parameter_recommendations.json for reference\")\n",
    "    print(f\"3. Update MoS2_UltraSensitive.ipynb with recommended parameters\")\n",
    "    print(f\"4. Re-run the pipeline on your new images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}